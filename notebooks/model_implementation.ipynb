{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906974db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from spoilernet import SpoilerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b4a337-48da-4643-83fc-957ca9f35d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9ac7b",
   "metadata": {},
   "source": [
    "## Read the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14cab344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4967400, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed_Sentence</th>\n",
       "      <th>Is_Spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>special book</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start slow first third middl third start get i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love good scienc fiction push think thing go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015 hugo winner translat origin chines made i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instanc intermix chines revolutionari histori ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Processed_Sentence  Is_Spoiler\n",
       "0                                       special book           0\n",
       "1  start slow first third middl third start get i...           0\n",
       "2       love good scienc fiction push think thing go           0\n",
       "3  2015 hugo winner translat origin chines made i...           0\n",
       "4  instanc intermix chines revolutionari histori ...           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../data/processed/review_context_final.json.gz\", compression='infer', lines=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d326b88",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af846fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4967400/4967400 [04:16<00:00, 19335.64it/s]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "current_index = 1\n",
    "\n",
    "for idx, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    sentence = row['Processed_Sentence']\n",
    "    words = sentence.split()\n",
    "    sentence_numeric = []\n",
    "\n",
    "    for word in words:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.add(word)\n",
    "            word_to_index[word] = current_index\n",
    "            index_to_word[current_index] = word\n",
    "            sentence_numeric.append(current_index)\n",
    "            current_index += 1\n",
    "        else:\n",
    "            sentence_numeric.append(word_to_index[word])\n",
    "\n",
    "    df.at[idx, 'Processed_Sentence'] = sentence_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbcb6aca-da76-45fb-9dfb-4744521f52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/word_to_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f)\n",
    "\n",
    "with open('../static/index_to_word.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_word, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422d2ee",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdff01a7-ce00-4d24-858c-d9eefafa858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3477180/3477180 [01:24<00:00, 41010.25it/s]\n",
      "100%|██████████| 745110/745110 [00:16<00:00, 45372.50it/s]\n",
      "100%|██████████| 745110/745110 [00:17<00:00, 41597.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([3477180, 122]), Labels shape: torch.Size([3477180])\n",
      "Validation data shape: torch.Size([745110, 76]), Labels shape: torch.Size([745110])\n",
      "Test data shape: torch.Size([745110, 78]), Labels shape: torch.Size([745110])\n"
     ]
    }
   ],
   "source": [
    "def extract_and_pad_data(dataframe):\n",
    "    sequences = list(dataframe['Processed_Sentence'])\n",
    "    labels = torch.tensor(dataframe['Is_Spoiler'].values).to(device)\n",
    "    padded_sequences = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor(sequence).to(device) for sequence in tqdm.tqdm(sequences, total=len(sequences))],\n",
    "        batch_first=True, padding_value=0).type(torch.LongTensor)\n",
    "\n",
    "    return padded_sequences, labels\n",
    "\n",
    "training_data, remaining_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "validation_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_features, train_labels = extract_and_pad_data(training_data)\n",
    "validation_features, validation_labels = extract_and_pad_data(validation_data)\n",
    "test_features, test_labels = extract_and_pad_data(test_data)\n",
    "\n",
    "print(f\"Training data shape: {train_features.shape}, Labels shape: {train_labels.shape}\")\n",
    "print(f\"Validation data shape: {validation_features.shape}, Labels shape: {validation_labels.shape}\")\n",
    "print(f\"Test data shape: {test_features.shape}, Labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763905a2",
   "metadata": {},
   "source": [
    "## Embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9eb491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 313517/313517 [1:55:22<00:00, 45.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# # this is a cpu intensive task as fasttext cannot run on gpus\n",
    "# # I ran this on my own computer and saved the embeddings\n",
    "# import fasttext\n",
    "# import fasttext.util\n",
    "# ft = fasttext.load_model('./static/cc.es.300.bin')\n",
    "\n",
    "# embedding_matrix = torch.zeros((current_index, 300))\n",
    "\n",
    "# for i, word in tqdm.tqdm(enumerate(vocabulary), total=len(vocabulary)):\n",
    "#     if word in ft:\n",
    "#         embedding_vector = torch.tensor(ft.get_word_vector(word))\n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "#     else:\n",
    "#         embedding_matrix[i] = torch.randn(300)\n",
    "\n",
    "# torch.save(embedding_matrix, './static/embedding_matrix.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5a0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.load('../static/embedding_matrix.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f653e15-3ca2-4751-9c8c-b5d754b990fa",
   "metadata": {},
   "source": [
    "## SpoilerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21742c28-5fd1-4cb7-a668-051890aed48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27166/27166 [10:28<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: 0.12911670388046248\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27166/27166 [10:27<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.12290414831694538\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27166/27166 [10:25<00:00, 43.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 2: 0.11942349402570614\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27166/27166 [10:25<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 3: 0.11629931952764284\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27166/27166 [10:25<00:00, 43.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 4: 0.11342593664740183\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters (proposed in the original paper)\n",
    "batch_size = 128\n",
    "embedding_dim = 300\n",
    "vocab_size = len(embedding_matrix)\n",
    "hidden_dim = 50\n",
    "gradient_clip_threshold = 50.0\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 5\n",
    "\n",
    "model = SpoilerNet(embedding_dim, hidden_dim, embedding_matrix).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "train_labels = train_labels.to(device)\n",
    "train_features = train_features.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(train_features, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for features_batch, labels_batch in tqdm.tqdm(train_loader):\n",
    "        features_batch = features_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(features_batch)\n",
    "        loss = loss_function(predictions.squeeze(), labels_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_threshold)\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"Loss at epoch {epoch}: {epoch_loss / len(train_loader)}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af237449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745110/745110 [11:56<00:00, 1039.85it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features = test_features.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "y_predictions = []\n",
    "y_probabilities = []\n",
    "correct_predictions = 0\n",
    "sigmoid = torch.nn.Sigmoid().to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for index in tqdm.tqdm(range(len(test_features))):\n",
    "    probabilities = sigmoid(model.forward(test_features[index].unsqueeze(0)))\n",
    "    prediction = torch.argmax(probabilities)\n",
    "    y_predictions.append(prediction.item())\n",
    "    y_probabilities.append(probabilities[0][0][1].item())\n",
    "\n",
    "    if prediction == test_labels[index]:\n",
    "        correct_predictions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fef4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.7458641313194289\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(test_labels.cpu().numpy(), y_probabilities)\n",
    "print(f\"ROC_AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b050f0-f456-4ee7-aef6-e838437e7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../models/complete_model.pth')\n",
    "torch.save(model.state_dict(), '../models/model_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
