{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0188e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Yuheng_Lu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289aaa19",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b6abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_json(\"../data/raw/goodreads_reviews_spoiler.json.gz\", compression='infer', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f1c432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1378033, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d552ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.iloc[:400000] # the full dataset is too large, we take around 1/3 of the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08cedc",
   "metadata": {},
   "source": [
    "## Preprocess raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c375ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 400000/400000 [2:01:44<00:00, 54.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, review in tqdm.tqdm(reviews_df.iterrows(), total=reviews_df.shape[0]):\n",
    "    processed_sentences = []\n",
    "    for sentence in review.review_sentences:\n",
    "        processed_text = ''\n",
    "        for word in sentence[1].split():\n",
    "            clean_word = word.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            clean_word = clean_word.replace('“', '').replace('”', '').replace('’', '').replace('…', '').replace('—', '')\n",
    "            if clean_word not in stopwords.words('english'):\n",
    "                stemmed_word = nltk.PorterStemmer().stem(clean_word)\n",
    "                if stemmed_word:\n",
    "                    processed_text += stemmed_word + ' '\n",
    "        processed_sentences.append([sentence[0], processed_text.strip()])\n",
    "    reviews_df.at[index, 'review_sentences'] = processed_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e8e04",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c235b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 400000/400000 [00:55<00:00, 7253.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed_Sentence</th>\n",
       "      <th>Is_Spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>special book</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start slow first third middl third start get i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love good scienc fiction push think thing go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015 hugo winner translat origin chines made i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instanc intermix chines revolutionari histori ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Processed_Sentence  Is_Spoiler\n",
       "0                                       special book           0\n",
       "1  start slow first third middl third start get i...           0\n",
       "2       love good scienc fiction push think thing go           0\n",
       "3  2015 hugo winner translat origin chines made i...           0\n",
       "4  instanc intermix chines revolutionari histori ...           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences, spoiler_tags = [], []\n",
    "for index, review in tqdm.tqdm(reviews_df.iterrows(), total=reviews_df.shape[0]):\n",
    "    for i in range(len(review.review_sentences)):\n",
    "        processed_sentences.append(review.review_sentences[i][1])\n",
    "        spoiler_tags.append(review.review_sentences[i][0])\n",
    "review_context_df = pd.DataFrame({\n",
    "    \"Processed_Sentence\": processed_sentences,\n",
    "    \"Is_Spoiler\": spoiler_tags\n",
    "})\n",
    "review_context_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b28bf5",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b914948",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_context_df.to_json(\"../data/processed/review_context_final.json.gz\", orient=\"records\", lines=True, compression=\"infer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
